### dbutils
def dbutils.secrets.get(scope, key) -> TaintSource[UserSecrets]: ...

def dbutils.secrets.getBytes(scope, key) -> TaintSource[UserSecrets]: ...

def dbutils.credentials.getCurrentCredentials() -> TaintSource[UserSecrets]: ...

#def dbutils.widgets.get(name) -> TaintSource[UserControlled]: ...

#def dbutils.widgets.getAll() -> TaintSource[UserControlled]: ...

def dbutils.jobs.taskValues.set(key, value: TaintSink[HTTPClientRequest_DATA]): ...

def dbutils.notebook.run(path, timeout_seconds, arguments: TaintSink[HTTPClientRequest_DATA]): ...

def dbutils.fs.mount(source, mountPoint, encryptionType, extraConfigs: TaintSink[Authentication, DataStorage]): ...

def dbutils.fs.put(file, contents: TaintSink[FileSystem_ReadWrite], overwrite): ...

### print/logging
def print(*objects: TaintSink[Logging, ReturnedToUser], sep, end, file, flush): ...

### botocore credentials
def boto3.session.Session.get_credentials() -> TaintSource[ServerSecrets]: ...

### Spark configs
def pyspark.sql.conf.RuntimeConfig.set(key, value: TaintSink[Authentication]): ...

### Spark DataFrame configs
def pyspark.sql.readwriter.DataFrameReader.load(self, path, format, schema, **options: TaintSink[Authentication]): ...

def pyspark.sql.readwriter.DataFrameReader.jdbc(self, url: TaintSink[Authentication], table, column, lowerBound, upperBound, numPartitions, predicates, properties: TaintSink[Authentication]): ...

def pyspark.sql.readwriter.DataFrameReader.option(self, key, value: TaintSink[Authentication]): ...

def pyspark.sql.readwriter.DataFrameReader.options(self, *, url: TaintSink[Authentication], **options): ...

def pyspark.sql.readwriter.DataFrameWriter.jdbc(self, url: TaintSink[Authentication], table, mode, properties: TaintSink[Authentication]): ...

def pyspark.sql.readwriter.DataFrameWriter.option(self, key: TaintSink[Authentication], value: TaintSink[Authentication]): ...

def pyspark.sql.readwriter.DataFrameWriter.options(self, *, url: TaintSink[Authentication], **options): ...

def pyspark.sql.readwriter.DataFrameWriter.save(self, path, format, mode, partitionBy, **options: TaintSink[Authentication]): ...

### DataFrame expressions
def pyspark.sql.session.SparkSession.sql(self, sqlQuery: TaintSink[SQL], **kwargs): ...

def pyspark.sql.dataframe.DataFrame.filter(self, condition: TaintSink[SQL]): ...

def pyspark.sql.dataframe.DataFrame.where(self, condition: TaintSink[SQL]): ...

def pyspark.sql.functions.expr(str: TaintSink[SQL]): ...

### Spark DataFrame show shouldn't alert for secrets in DataFrame reader
def pyspark.sql.dataframe.DataFrame.show(self: Sanitize[TaintSource[UserSecrets,ServerSecrets]], n, truncate, vertical): ...
